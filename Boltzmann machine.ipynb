{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Boltzmann machine\n",
    "\n",
    "## A short introduction\n",
    "\n",
    "A Boltzmann machine is a _symmetric binary stochastic neural network_. This means that the nodes (also called neurons) of the network can only assume one of two possible states, namely 1 and 0 or, equivalently, \"on\" and \"off\" (__binary property__). At each iteration step, the state of such a neuron is switched on (or kept on) with a certain __probability p__ (__stochastic property__). Intuitively, a neuron should more likely to be active (i.e. in the \"on\" state) if it receives a lot of input. This is exactly what is the case in the Boltzmann machine, where the probability $p(s_i)$ that neuron $i$ is in state $s=1^{[1],[2]}$:\n",
    "\n",
    "$$p(s_i=1) = \\frac{1}{1+e^{-\\frac{z_i}{T}}},$$\n",
    "\n",
    "where\n",
    "\n",
    "$$z_i = b_i + \\sum_{j}^N s_j\\omega_{ij}, \\,\\,\\, \\omega_{ii} = 0.$$\n",
    "\n",
    "$z_i$ is the input that unit $i$ receives (where bias acts as input as well). Here, $s_j$ is the state of neuron $j$, $N$ is the number of neurons in the network, $b_i$ is the _bias_ of neuron $i$ and $\\omega_{ij}$ is the connection strength from neuron $j$ to neuron $i$. Importantly connections are symmetric, i.e. $\\omega_{ij}=\\omega_{ji}$ (__symmetric property__). $T$ is the system temperature. It determines the slope of the sigmoid function $p(s_i = 1)$, which turns into the Heaviside stepfunction for $T \\rightarrow 0$:\n",
    "\n",
    "![Activation function of unit i](./sigmoid.png)\n",
    "\n",
    "The state of the network is completely described by state vector $\\vec{s}=(s_1, s_2, ..., s_n)^T$, $s_i\\in{0,1}$.\n",
    "\n",
    "Before coming to the eponymous feature of the Boltzmann machine, we first have to introduce the concept of the _energy_ of the network. Each state $\\vec{s}$ is associated with a scalar function called the state's _energy_ E($\\vec{s}$):\n",
    "\n",
    "$$E(\\vec{s}) = -\\sum_i s_i b_i - \\sum_{i \\lt j} s_is_j\\omega_{ij},$$\n",
    "where\n",
    "$$\\sum_{i \\lt j} s_is_j\\omega_{ij} \\doteq  \\sum_{i=1}^j \\sum_{j=2}^N s_is_j\\omega_{ij},$$\n",
    "\n",
    "The energy of a state is thus __the negative sum of the biases of all active neurons minus the sum of connection weights of connections whose neurons on both ends are active__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Some words about the energy function</b>\n",
    "\n",
    "Why is $E(\\vec{s})$ called the energy? It's called energy because it behaves like a physical energy: it's a scalar function whcih the system tends to minimize. How can we see that the energy is actually minimized by the system? To understand this, it is helpful to realise that the input $z_i$ to a neuron is is equal to the amount by which $E(\\vec{s})$ is reduced, when unit $i$ turns from off to on:\n",
    "\n",
    "$$E(s_i = 0)-E(s_i=1) = z_i.$$\n",
    "\n",
    "Now consider the case $T\\rightarrow 0$, for which the probability of a neuron being on turns into a step function (Fig. 1): If $z_i>0$ (which means that a switching on of the state would reduce the energy function), the state is set to \"on\" with 100% certainty. If $z_i<0$ (which means that a switching on of the state would increase the energy function), the state is set to \"off\" with certainty. If $T<<\\infty$, then this behaviour is not deterministic anymore, but as $z_i>0$ still means that state $i$ will be on most of the time ($z_i > 0 \\rightarrow p(z_i)>0.5$), the system _tends_ to minimize its energy function.\n",
    "\n",
    "It is however hard, if not impossible, to easily say what configuration the system takes to assume. In the simple case where all biases are greater or equal to zero, and all connection weights are larger than zero, it is easy to see that a minimization of the energy is equivalent to a turning on of all neurons. Similarly the system tends to turn neurons off if biases and weights are all negative. In the case however where biases and/ or weights can be both negative and positive, the energy-minimizing configuration is not that easy to see.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the neuronal states of the network are updated in a way that is not dependent on the states, the network will eventually settle in a __Boltzmann distribution__. This means, that the occurrence probability $p(\\vec{s})$ of a state vector $\\vec{s}$ is dependent only to its energy:\n",
    "\n",
    "$$p(\\vec{s}) = \\frac{e^{-E(\\vec{s})}}{\\sum_\\vec{u}e^{-E(\\vec{u})}} \\ \\ \\ \\ \\ \\ (1)$$\n",
    "\n",
    "where $\\sum_\\vec{u}$ is the sum over all possible network states. Note that $p(\\vec{s})$ is proportional to the exponential of the state's negative energy, as $\\sum_\\vec{u}e^{-E(\\vec{u})} = const$. The distribution for $p(\\vec{s})$ derives its name from the similar-looking [Boltzmann Distribution](https://en.wikipedia.org/wiki/Boltzmann_distribution) from statistical mechanics, which describes the probability of occurrence of a physical state in a thermodynamical system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n",
    "\n",
    "## Learning without Hidden Units\n",
    "\n",
    "The learning rules for the connection strengths and biases of a Boltzmann machine without hidden units are$^{[1]}$:\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Learning rules (without hidden units)</b>\n",
    "$$\\Delta \\omega_{ij} = \\alpha_\\omega \\cdot \\left( \\langle s_i s_j \\rangle_{data} - \\langle s_i s_j \\rangle_{model} \\right)$$\n",
    "$$\\Delta b_i = \\alpha_b \\cdot \\left( \\langle s_j \\rangle_{data} - \\langle s_j \\rangle_{model} \\right)$$\n",
    "    </div>\n",
    "Here $\\alpha_\\omega$ and $\\alpha_b$ are the learning rates, and _model_ stands for Boltzmann machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] [Geoffrey E. Hinton (2007) Boltzmann machine. Scholarpedia, 2(5):1668.](http://www.scholarpedia.org/article/Boltzmann_machine)\n",
    "\n",
    "[2] [Wikipedia: Boltzmann machine](https://en.wikipedia.org/wiki/Boltzmann_machine)\n",
    "\n",
    "# Further Reading\n",
    "\n",
    "- https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf\n",
    "\n",
    "- http://rocknrollnerd.github.io/ml/2015/07/18/general-boltzmann-machines.html\n",
    "\n",
    "- https://www.enterrasolutions.com/media/docs/2013/08/cogscibm.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## Approximation to the Boltzmann Distribution\n",
    "\n",
    "We want to check that the Boltzmann machine (BM) actually generates state vectors with their respective boltzmann-probabilities (equation (1)). This should be the case after the BM had the chance to settle into its stable state, thus after a certain number of iterations. The longer it iterates (i.e. generates data), the closer it should be to the Boltzmann distribution.\n",
    "\n",
    "In the following we will check whether the average distance between the boltzmann-probabilities of binary states with 10 entries and their probabilities of being generated by the (randomly initialised) BM actually decreases with more iterations.\n",
    "\n",
    "Note: The following is merely a proof of principle and not a strict mathematical proof the boltzmann property!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1484.71it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 2112.07it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 1310.83it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 1810.08it/s]\n",
      "100%|██████████| 125/125 [00:00<00:00, 2255.53it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 2491.11it/s]\n",
      "100%|██████████| 343/343 [00:00<00:00, 2244.51it/s]\n",
      "100%|██████████| 512/512 [00:00<00:00, 2420.86it/s]\n",
      "100%|██████████| 729/729 [00:00<00:00, 2445.25it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2420.84it/s]\n",
      "100%|██████████| 1331/1331 [00:00<00:00, 2464.08it/s]\n",
      "100%|██████████| 1728/1728 [00:00<00:00, 2475.04it/s]\n",
      "100%|██████████| 2197/2197 [00:00<00:00, 2307.15it/s]\n",
      "100%|██████████| 2744/2744 [00:01<00:00, 2448.73it/s]\n",
      "100%|██████████| 3375/3375 [00:01<00:00, 2416.63it/s]\n",
      "100%|██████████| 4096/4096 [00:01<00:00, 2360.40it/s]\n",
      "100%|██████████| 4913/4913 [00:02<00:00, 2449.89it/s]\n",
      "100%|██████████| 5832/5832 [00:02<00:00, 2476.71it/s]\n",
      "100%|██████████| 6859/6859 [00:02<00:00, 2430.02it/s]\n",
      "100%|██████████| 8000/8000 [00:03<00:00, 2450.41it/s]\n",
      "100%|██████████| 9261/9261 [00:03<00:00, 2435.78it/s]\n",
      "100%|██████████| 10648/10648 [00:04<00:00, 2418.51it/s]\n",
      "100%|██████████| 12167/12167 [00:05<00:00, 2389.20it/s]\n",
      "100%|██████████| 13824/13824 [00:05<00:00, 2357.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import BM #import Boltzmann Machine script (from this repository)\n",
    "import numpy as np\n",
    "N = 10 # There are 1024 different binary state vectors of length 10\n",
    "\n",
    "iterations = [i**3 for i in range(1,25)]\n",
    "distances = []\n",
    "\n",
    "for no_of_iterations in iterations:\n",
    "    bm = BM.BoltzmannM(N, initial_state=np.ones(N)) # Initialise BM (random weights and biases are automatically assigned)\n",
    "    \n",
    "    laststate, state_history = bm.iterate(no_of_iterations, savehist=True, suppress_output=True) # Iterate \n",
    "\n",
    "    import itertools\n",
    "    all_possible_states = [list(i) for i in itertools.product([0, 1], repeat=N)] # Create a list of all 1024 possible states\n",
    "    energies = bm.energy(all_possible_states) # Use the method energy() to compute the energy for each element in the list (Here an element is a list of length 10)\n",
    "\n",
    "    boltzmann_probs = []\n",
    "    for idx, state in enumerate(all_possible_states):\n",
    "        boltzmann_probability = np.exp(-energies[idx])/np.exp(-np.array(energies)).sum()\n",
    "        boltzmann_probs.append(boltzmann_probability)\n",
    "\n",
    "    # boltzmann_probs now contains the boltzmann-probabilities for the states in all_possible_states\n",
    "    # Compute the probability of a state actually being generated by the model\n",
    "\n",
    "    model_probs = []\n",
    "    for state in all_possible_states:\n",
    "        occurences_in_history = [1 for s in state_history if s == state]\n",
    "        model_probs.append(sum(occurences_in_history)/no_of_iterations)\n",
    "\n",
    "    # model_probs now contains the probabilities of occurrence for the states in state_history (generated by the BM)\n",
    "\n",
    "    # The average distance between the probabilities is thus \n",
    "    average_distance = (abs(np.array(boltzmann_probs) - np.array(model_probs))).mean()\n",
    "    distances.append(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6fdd43b5b0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(iterations,distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation of the Learning Rules\n",
    "The learning rates can be derived as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\langle \\frac{\\partial}{\\partial \\omega_{ij}} \\ln p(\\vec{v})\\rangle_{data} = \\langle \\frac{\\partial}{\\partial \\omega_{ij}}\\left( -E(\\vec{v}) -\\ln \\sum_{\\vec{u}} e^{-E(\\vec{u})} \\right) \\rangle_{data} \\ \\ \\ \\ \\ \\ (2)\n",
    "\\end{align}\n",
    "$$\n",
    "Here, we used the identity of Equation (1) above. $\\langle \\cdot \\rangle_{data}$ stands for the expected value under the distribution of state vectors $\\vec{v}$ in the data. We can thus rewrite the above equation as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{\\vec{v}} p_{data}(\\vec{v})\\left( \\frac{\\partial}{\\partial \\omega_{ij}}\\left( -E(\\vec{v}) -\\ln \\sum_{\\vec{u}} e^{-E(\\vec{u})} \\right) \\right)  \\ \\ \\ \\ \\ \\ (3)\n",
    "\\end{align}\n",
    "$$\n",
    "In the previous equation $p_{data}(\\vec{v})$ stands for the probability of state vector $\\vec{v}$ occurring in the training data and must therefore not be confused with the boltzmann distribution in equation (1) above.\n",
    "\n",
    "For the next step we use the fact that $\\frac{\\partial}{\\partial \\omega_{ij}}E(\\vec{v})=-s_is_j$. At the same time we use $\\frac{\\partial}{\\partial \\omega_{ij}} \\ln \\sum_{\\vec{u}}e^{-E(\\vec{u})} = \\frac{\\frac{\\partial}{\\partial \\omega_{ij}} \\sum_{\\vec{u}}e^{-E(\\vec{u})}}{\\sum_{\\vec{u}}e^{-E(\\vec{u})}}$, because of $\\frac{\\partial}{\\partial x} \\ln(f(x)) = \\frac{\\frac{\\partial}{\\partial x} f(x)}{f(x)}$. Thus, equation (3) can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{\\vec{v}} p_{data}(\\vec{v})(s_is_j)_\\vec{v} - \\sum_{\\vec{v}} p_{data}(\\vec{v}) \\frac{\\frac{\\partial}{\\partial \\omega_{ij}} \\sum_{\\vec{u}}e^{-E(\\vec{u})}}{\\sum_{\\vec{u}}e^{-E(\\vec{u})}}  \\ \\ \\ \\ \\ \\ (4).\n",
    "\\end{align}\n",
    "$$\n",
    "Now this is starting to look a little complicated, but upon closer inspection we see that the left hand side is simply the expectation value of $s_is_j$ under the state-distribution of the data, and the right-hand side is independent of the vector $\\vec{v}$ we started with. Therefore, the sum on the RHS just sums to one and equation (4) can be rewritten as (writing the derivative inside the sum):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\langle s_is_j \\rangle_{data} - \\frac{\\sum_{\\vec{u}} \\frac{\\partial}{\\partial \\omega_{ij}} e^{-E(\\vec{u})}}{\\sum_{\\vec{u}}e^{-E(\\vec{u})}}  \\ \\ \\ \\ \\ \\ (5).\n",
    "\\end{align}\n",
    "$$\n",
    "Derivation as before gives:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\langle s_is_j \\rangle_{data} - \\frac{\\sum_{\\vec{u}} (s_is_j)_\\vec{u}\\cdot e^{-E(\\vec{u})}}{\\sum_{\\vec{u}}e^{-E(\\vec{u})}}  = \\langle s_is_j \\rangle_{data} - \\sum_\\vec{u}\\left( p(\\vec{u})\\cdot(s_is_j)_\\vec{u}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the last step we used the definition of the Boltzmann distribution from euqation (1). As the distribution describes the distribution of state vectors of the Boltzmann machine (which is the _model_), the LHS of equation resolves to:\n",
    "\n",
    "$$\\langle \\frac{\\partial}{\\partial \\omega_{ij}} \\ln p(\\vec{v})\\rangle_{data} = \\langle s_is_j \\rangle_{data} - \\langle s_is_j \\rangle_{model}.$$\n",
    "\n",
    "The learning rule for $b_i$ can be derived analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "Hebbian Learning\n",
    "\n",
    "Hopfield networks\n",
    "\n",
    "Do not directly compute the partition function as it will quickly be a sum over an impossibly large number of possible state vectors (1267650600228229682971679916032 different states for N = 100 neurons). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
